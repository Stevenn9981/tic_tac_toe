{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Stevenn9981/tic_tac_toe/blob/master/tic_tac_toe_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEy_PMnnf-Og"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdG6QronfqnR",
    "outputId": "995d56e8-1bb2-448b-bbd5-691a718e82fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/110 kB 13%] [Connect\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [47.6 kB]\n",
      "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
      "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [632 kB]\n",
      "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,494 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,265 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,027 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,535 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,520 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,292 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\n",
      "Fetched 9,186 kB in 3s (3,219 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "The following additional packages will be installed:\n",
      "  freeglut3 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev\n",
      "  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n",
      "  libglx-dev libice-dev libopengl-dev libsm-dev libxfont2 libxkbfile1\n",
      "  libxt-dev x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
      "  xserver-common\n",
      "Suggested packages:\n",
      "  libice-doc libsm-doc libxt-doc\n",
      "The following NEW packages will be installed:\n",
      "  freeglut3 freeglut3-dev libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n",
      "  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
      "  libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev libxfont2\n",
      "  libxkbfile1 libxt-dev x11-xkb-utils xfonts-base xfonts-encodings\n",
      "  xfonts-utils xserver-common xvfb\n",
      "0 upgraded, 25 newly installed, 0 to remove and 19 not upgraded.\n",
      "Need to get 9,075 kB of archives.\n",
      "After this operation, 18.7 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.0.4-0ubuntu1~22.04.1 [6,510 B]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.2 [28.1 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.2 [864 kB]\n",
      "Fetched 9,075 kB in 3s (3,209 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 25.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package freeglut3:amd64.\n",
      "(Reading database ... 120882 files and directories currently installed.)\n",
      "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
      "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
      "Selecting previously unselected package libglx-dev:amd64.\n",
      "Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl-dev:amd64.\n",
      "Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
      "Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libegl-dev:amd64.\n",
      "Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgles1:amd64.\n",
      "Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgles-dev:amd64.\n",
      "Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libopengl-dev:amd64.\n",
      "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libglvnd-dev:amd64.\n",
      "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
      "Preparing to unpack .../09-libgl1-mesa-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Selecting previously unselected package libglu1-mesa:amd64.\n",
      "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
      "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
      "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
      "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
      "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
      "Selecting previously unselected package libice-dev:amd64.\n",
      "Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
      "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
      "Selecting previously unselected package libsm-dev:amd64.\n",
      "Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
      "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
      "Selecting previously unselected package libxt-dev:amd64.\n",
      "Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
      "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
      "Selecting previously unselected package freeglut3-dev:amd64.\n",
      "Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
      "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
      "Selecting previously unselected package libfontenc1:amd64.\n",
      "Preparing to unpack .../16-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
      "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
      "Selecting previously unselected package libxfont2:amd64.\n",
      "Preparing to unpack .../17-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
      "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
      "Selecting previously unselected package libxkbfile1:amd64.\n",
      "Preparing to unpack .../18-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
      "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
      "Selecting previously unselected package x11-xkb-utils.\n",
      "Preparing to unpack .../19-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
      "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
      "Selecting previously unselected package xfonts-encodings.\n",
      "Preparing to unpack .../20-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
      "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "Selecting previously unselected package xfonts-utils.\n",
      "Preparing to unpack .../21-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
      "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
      "Selecting previously unselected package xfonts-base.\n",
      "Preparing to unpack .../22-xfonts-base_1%3a1.0.5_all.deb ...\n",
      "Unpacking xfonts-base (1:1.0.5) ...\n",
      "Selecting previously unselected package xserver-common.\n",
      "Preparing to unpack .../23-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.2_all.deb ...\n",
      "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
      "Selecting previously unselected package xvfb.\n",
      "Preparing to unpack .../24-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.2_amd64.deb ...\n",
      "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
      "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
      "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
      "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
      "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
      "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
      "Setting up libgles1:amd64 (1.4.0-1) ...\n",
      "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
      "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
      "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
      "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
      "Setting up x11-xkb-utils (7.7+5build4) ...\n",
      "Setting up xfonts-utils (1:7.7+6build2) ...\n",
      "Setting up xfonts-base (1:1.0.5) ...\n",
      "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
      "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
      "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
      "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
      "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.23.5)\n",
      "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
      "Collecting pyvirtualdisplay\n",
      "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pyvirtualdisplay\n",
      "Successfully installed pyvirtualdisplay-3.0\n",
      "Collecting tf-agents[reverb]\n",
      "  Downloading tf_agents-0.18.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
      "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
      "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents[reverb])\n",
      "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.23.5)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (9.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
      "Collecting pygame==2.1.3 (from tf-agents[reverb])\n",
      "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-probability~=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.22.0)\n",
      "Collecting rlds (from tf-agents[reverb])\n",
      "  Downloading rlds-0.1.8-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-reverb~=0.13.0 (from tf-agents[reverb])\n",
      "  Downloading dm_reverb-0.13.0-cp310-cp310-manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow~=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.14.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.13.0->tf-agents[reverb]) (0.1.8)\n",
      "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.13.0->tf-agents[reverb]) (1.5.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (23.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (67.7.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tf-agents[reverb]) (4.4.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.14.0->tf-agents[reverb]) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.0.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker->dm-reverb~=0.13.0->tf-agents[reverb]) (5.9.5)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.2.2)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697630 sha256=b01f2820399ad5e2761719ff4a8c006b56d8b12ff2b8a736f047d850bb349eba\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
      "Successfully built gym\n",
      "Installing collected packages: rlds, pygame, gym, tf-agents, dm-reverb\n",
      "  Attempting uninstall: pygame\n",
      "    Found existing installation: pygame 2.5.2\n",
      "    Uninstalling pygame-2.5.2:\n",
      "      Successfully uninstalled pygame-2.5.2\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.25.2\n",
      "    Uninstalling gym-0.25.2:\n",
      "      Successfully uninstalled gym-0.25.2\n",
      "Successfully installed dm-reverb-0.13.0 gym-0.23.0 pygame-2.1.3 rlds-0.1.8 tf-agents-0.18.0\n",
      "Collecting pyglet\n",
      "  Downloading pyglet-2.0.10-py3-none-any.whl (858 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.3/858.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyglet\n",
      "Successfully installed pyglet-2.0.10\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
    "!pip install imageio\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install tf-agents[reverb]\n",
    "!pip install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-vtSiPUgOOU",
    "outputId": "57186d44-9a01-4a6c-e692-cb879b42e9c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "import reverb\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile\n",
    "import copy\n",
    "\n",
    "import pygame as pg\n",
    "from pygame import gfxdraw\n",
    "from pygame.locals import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.networks import categorical_q_network\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.trajectories import PolicyStep\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.trajectories import time_step as ts, TimeStep\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "tempdir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "id": "MsV4e7iqg10s",
    "outputId": "942abf55-b464-4e3a-88b9-356437498efe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWwU8Wp7g2_X"
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "reKJx_ybg7_L"
   },
   "outputs": [],
   "source": [
    "num_iterations = 1200  # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "initial_collect_episodes = 5  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "collect_episodes_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 10000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 128  # @param {type:\"integer\"}\n",
    "learning_rate = 5e-4  # @param {type:\"number\"}\n",
    "log_interval = 5  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 50  # @param {type:\"integer\"}\n",
    "eval_interval = 20  # @param {type:\"integer\"}\n",
    "\n",
    "gamma = 0  # @param {type:\"number\"}\n",
    "n_step_update = 1  # @param {type:\"integer\"}\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "BOARD_SIZE = 9  # @param {type:\"integer\"}\n",
    "\n",
    "REWARD_DRAW = 0  # @param {type:\"number\"}\n",
    "REWARD_ALIVE = 0  # @param {type:\"number\"}\n",
    "REWARD_NON_ADJ = -0.03  # @param {type:\"number\"}\n",
    "\n",
    "# '_' means empty position, 'O' and 'X' means two players.\n",
    "REWARD_ACTIVE_TWO = 0.1  # @param {type:\"number\"} _OO_ or _XX_, we call it active_two\n",
    "REWARD_NONACT_THREE = 0.3  # @param {type:\"number\"} _OOOX or _XXXO or XOOO_ or OXXX_, we call it non_active_three\n",
    "REWARD_ACTIVE_THREE = 0.9  # @param {type:\"number\"} _OOO_ or _XXX_, we call it active_three\n",
    "REWARD_WIN = 3  # @param {type:\"number\"} _OOOO_ or _XXXX_\n",
    "\n",
    "tempdir = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOBVDKmMIcyJ"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aq7Q2oxyIhS8"
   },
   "outputs": [],
   "source": [
    "class TicTacToeEnv2(py_environment.PyEnvironment):\n",
    "    \"\"\"\n",
    "    Implementation of a TicTacToe Environment based on the instructions of Part 2, Question 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train=False) -> None:\n",
    "        \"\"\"This class contains a TicTacToe environment for Part 2\n",
    "\n",
    "        Args:\n",
    "            train (bool): whether this is an environment for training.\n",
    "        \"\"\"\n",
    "\n",
    "        self.ener_bin_len = 0.2\n",
    "        self.num_bin = int(1 / self.ener_bin_len) + 1\n",
    "        self.n_actions = BOARD_SIZE * BOARD_SIZE * self.num_bin  # 9 * 9 * self.num_bin actions\n",
    "\n",
    "        self._observation_spec = {\n",
    "            'state': array_spec.BoundedArraySpec(shape=(BOARD_SIZE, BOARD_SIZE, 5), dtype=np.int_, minimum=0,\n",
    "                                                 maximum=1),\n",
    "            'legal_moves': array_spec.ArraySpec(shape=(self.n_actions,), dtype=np.bool_)}\n",
    "\n",
    "        self._action_spec = array_spec.BoundedArraySpec(shape=(), dtype=np.int_, minimum=0, maximum=self.n_actions - 1)\n",
    "        self.colors = [1, 2]\n",
    "        self.screen = None\n",
    "        self.fields_per_side = BOARD_SIZE\n",
    "        self.train = train\n",
    "        self.reset()\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def get_result(self):\n",
    "        return self.result\n",
    "\n",
    "    def _reset(self) -> TimeStep:\n",
    "        \"\"\"\n",
    "        reset the board game and state\n",
    "        \"\"\"\n",
    "        self.board: np.ndarray = np.zeros(\n",
    "            (self.fields_per_side, self.fields_per_side), dtype=int\n",
    "        )\n",
    "        self.current_player = 1\n",
    "        self.info = {\"players\": {1: {\"energy\": 10}, 2: {\"energy\": 10}}, \"Occupied\": set(),\n",
    "                     \"legal_moves\": np.ones((self.n_actions,), dtype=bool)}\n",
    "        self.latest_action = None\n",
    "\n",
    "        # 0 means not finished, 1 or 2 means the winner and 3 means draw\n",
    "        self.result = 0\n",
    "\n",
    "        # return self.decompose_board_to_state()\n",
    "        observations_and_legal_moves = {'state': self.decompose_board_to_state(),\n",
    "                                        'legal_moves': self.info[\"legal_moves\"]}\n",
    "        return ts.restart(observations_and_legal_moves)\n",
    "\n",
    "    def if_chess_nearby(self, row, col) -> bool:\n",
    "        \"\"\"\n",
    "        Determine whether there are chess pieces in 2 squares around the given position (row, col)\n",
    "\n",
    "        Args:\n",
    "          row (int): row index\n",
    "          col (int): column index\n",
    "\n",
    "        Returns:\n",
    "          res (boolean): true, if there are\n",
    "        \"\"\"\n",
    "        for i in range(-2, 3):\n",
    "            for j in range(-2, 3):\n",
    "                if 0 <= row + i < BOARD_SIZE and 0 <= col + j < BOARD_SIZE:\n",
    "                    if self.board[row + i, col + j] != 0:\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    def decompose_board_to_state(self):\n",
    "        \"\"\"\n",
    "        Our state is a 9x9x5 matrix.\n",
    "        The first layer is the opponent's play history, 0 means no stone, 1 means stones placed by the opponent.\n",
    "        The second layer is the current player's history, 0 means no stone, 1 means stones placed by the current player.\n",
    "        The third layer is the opponent's latest play-out; only one entry is 1 and the others are 0. If the board is empty now, all entries are 0.\n",
    "        The fourth layer is whether the current player is the first hand. an array that is full of 1 means yes, and 0 means no.\n",
    "        The fifth layer shows the empty positions whose adjacent positions are not all empty. 1 means there is at least one chess piece in its adjacent positions, and 0 means no.\n",
    "        \"\"\"\n",
    "        opponent = 2 if self.current_player == 1 else 1\n",
    "        o_plays = (self.board == opponent) * 1\n",
    "        c_plays = (self.board == self.current_player) * 1\n",
    "        l_play = np.zeros_like(self.board)\n",
    "        if self.latest_action:\n",
    "            r, c, _ = self.decode_action(self.latest_action)\n",
    "            l_play[r, c] = 1\n",
    "        if_first = np.full_like(self.board, (self.current_player == 1) * 1)\n",
    "        adj_play = np.zeros_like(self.board)\n",
    "        for row in range(adj_play.shape[0]):\n",
    "            for col in range(adj_play.shape[1]):\n",
    "                if self.board[row, col] == 0 and self.if_chess_nearby(row, col):\n",
    "                    adj_play[row, col] = 1\n",
    "        return np.stack([o_plays, c_plays, l_play, if_first, adj_play], axis=2)\n",
    "\n",
    "    def _step(self, position: int) -> Tuple[np.ndarray, int, bool, dict]:\n",
    "        \"\"\"step function of the TicTacToeEnv2\n",
    "\n",
    "        Args:\n",
    "          position (int): integer between [0, 80], each representing a field on the board\n",
    "\n",
    "        Returns:\n",
    "          state (np.array): state of 2 players' history, 0 means no stone, 1 means stones placed by the corresponding player (shape: 9x9x2).\n",
    "          reward (int): reward of the currrent step\n",
    "          done (boolean): true, if the game is finished\n",
    "          (dict): empty dict for future game related information\n",
    "        \"\"\"\n",
    "        position = int(position)\n",
    "        if not (0 <= position < self.n_actions):\n",
    "            raise ValueError(f\"action '{position}' is not in action_space\")\n",
    "\n",
    "        reward = REWARD_ALIVE\n",
    "        (row, col, ener) = self.decode_action(position)\n",
    "        energy_to_use = ener * self.ener_bin_len\n",
    "\n",
    "        # If the agent/player does not choose an empty square, raise the ValueError.\n",
    "        if self.board[row, col] != 0:\n",
    "            if len(self.info[\"Occupied\"]) == BOARD_SIZE * BOARD_SIZE:\n",
    "                raise ValueError('BORAD IS FULL!')\n",
    "            raise ValueError('ERROR: Not A LEGAL MOVE (NOT EMPTY)')\n",
    "\n",
    "        # Check whether there is enough energy to use for the current player\n",
    "        if self.info[\"players\"][self.current_player][\"energy\"] < energy_to_use:\n",
    "            energy_to_use = self.info[\"players\"][self.current_player][\"energy\"]\n",
    "        self.info[\"players\"][self.current_player][\"energy\"] -= energy_to_use\n",
    "\n",
    "        # randomly select an adjacent position with probability 1/8 * (8 / 9 - 6 / 9 * energy_to_use)\n",
    "        if random.random() < (1 - 1 / 9 - 6 / 9 * energy_to_use):\n",
    "            row, col = self.choose_adj_pos(row, col)\n",
    "\n",
    "        # if len(self.info[\"Occupied\"]) != 0 and not self.if_chess_nearby(row, col):\n",
    "        #     reward += REWARD_NON_ADJ\n",
    "\n",
    "        win = False\n",
    "        if 0 <= row < BOARD_SIZE and 0 <= col < BOARD_SIZE and self.board[row, col] == 0:\n",
    "            self.board[row, col] = self.current_player  # drop the piece on the field\n",
    "            win = self._is_win(self.current_player, row, col)\n",
    "\n",
    "            cnt_act_two = self.detect_alive_two(row, col)\n",
    "            cnt_non_act_three, cnt_act_three = self.detect_three(row, col)\n",
    "\n",
    "            reward += (\n",
    "                    cnt_act_two * REWARD_ACTIVE_TWO + cnt_non_act_three * REWARD_NONACT_THREE + cnt_act_three * REWARD_ACTIVE_THREE)\n",
    "\n",
    "            position = row * BOARD_SIZE + col\n",
    "            num_places = BOARD_SIZE * BOARD_SIZE\n",
    "\n",
    "            self.latest_action = int(position + energy_to_use / self.ener_bin_len * num_places)\n",
    "            for i in range(self.num_bin):\n",
    "                action = position + i * num_places\n",
    "                self.info[\"Occupied\"].add(action)\n",
    "                self.info['legal_moves'][action] = False\n",
    "        elif self.latest_action:\n",
    "            r, c, _ = self.decode_action(self.latest_action)\n",
    "            self.latest_action = int(r * BOARD_SIZE + c + energy_to_use / self.ener_bin_len * BOARD_SIZE * BOARD_SIZE)\n",
    "\n",
    "        if win:\n",
    "            self.result = self.current_player\n",
    "            reward += REWARD_WIN\n",
    "        elif len(self.info[\"Occupied\"]) == BOARD_SIZE * BOARD_SIZE:  # Draw\n",
    "            self.result = 3\n",
    "            reward += REWARD_DRAW\n",
    "\n",
    "        done = (win or len(self.info[\"Occupied\"]) == BOARD_SIZE * BOARD_SIZE)\n",
    "        self.current_player = self.current_player + 1 if self.current_player == 1 else 1\n",
    "        state = self.decompose_board_to_state()\n",
    "\n",
    "        observations_and_legal_moves = {'state': state, 'legal_moves': self.info['legal_moves']}\n",
    "\n",
    "        if done:\n",
    "            return ts.termination(observations_and_legal_moves, reward)\n",
    "        else:\n",
    "            return ts.transition(observations_and_legal_moves, reward)\n",
    "\n",
    "    def detect_alive_two(self, row: int, col: int) -> int:\n",
    "        \"\"\" Detect how many alive_two can obtain by this play out.\n",
    "\n",
    "        Args:\n",
    "            row (int): row of the current play\n",
    "            col (int): column of the current play\n",
    "\n",
    "        Returns:\n",
    "            cnt (int): the number of alive_two\n",
    "        \"\"\"\n",
    "        cnt = 0\n",
    "        adjs = [[-1, -1], [-1, 0], [-1, 1], [0, 1], [0, -1], [1, -1], [1, 0], [1, 1]]\n",
    "        for adj in adjs:\n",
    "            p1_r, p1_c = row + 2 * adj[0], col + 2 * adj[1]\n",
    "            p2_r, p2_c = row - adj[0], col - adj[1]\n",
    "            if 0 <= p1_r < 9 and 0 <= p1_c < 9 and 0 <= p2_r < 9 and 0 <= p2_c < 9:\n",
    "                if self.board[row + adj[0], col + adj[1]] == self.current_player and self.board[p1_r, p1_c] == 0 and \\\n",
    "                        self.board[p2_r, p2_c] == 0:\n",
    "                    cnt += 1\n",
    "        return cnt\n",
    "\n",
    "    def detect_three(self, r: int, c: int) -> tuple:\n",
    "        \"\"\" Detect how many non_active_three and active_three can obtain by this play out.\n",
    "\n",
    "        Args:\n",
    "            r (int): row of the current play\n",
    "            c (int): column of the current play\n",
    "\n",
    "        Returns:\n",
    "            cnt_non_act (int): the number of non_active_three\n",
    "            cnt_act (int): the number of active_three\n",
    "        \"\"\"\n",
    "        cnt_non_act = 0\n",
    "        cnt_act = 0\n",
    "        opponent = self.current_player + 1 if self.current_player == 1 else 1\n",
    "        directions = [[0, 1], [1, 0], [1, 1], [1, -1]]\n",
    "\n",
    "        for direct in directions:\n",
    "            count = 0\n",
    "            for offset in range(-2, 3):\n",
    "                if 0 <= r + offset * direct[0] < 9 and 0 <= c + offset * direct[1] < 9:\n",
    "                    if self.board[r + offset * direct[0], c + offset * direct[1]] == self.current_player:\n",
    "                        count += 1\n",
    "                        if count == 3:\n",
    "                            p1_r, p1_c = r + (offset + 1) * direct[0], c + (offset + 1) * direct[1]\n",
    "                            p2_r, p2_c = r + (offset - 3) * direct[0], c + (offset - 3) * direct[1]\n",
    "\n",
    "                            p1_is_empty = (0 <= p1_r < 9 and 0 <= p1_c < 9 and self.board[p1_r, p1_c] == 0)\n",
    "                            p2_is_empty = (0 <= p2_r < 9 and 0 <= p2_c < 9 and self.board[p2_r, p2_c] == 0)\n",
    "\n",
    "                            if p1_is_empty and p2_is_empty:\n",
    "                                cnt_act += 1\n",
    "                            elif p1_is_empty or p2_is_empty:\n",
    "                                cnt_non_act += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        count = 0\n",
    "\n",
    "        return cnt_non_act, cnt_act\n",
    "\n",
    "    def choose_adj_pos(self, row: int, col: int) -> tuple:\n",
    "        \"\"\" Randomly select an adjacent position with equal probabilities.\n",
    "\n",
    "        Args:\n",
    "            row (int): row of the current play\n",
    "            col (int): column of the current play\n",
    "\n",
    "        Returns:\n",
    "            row (int): row of the selected adjacent position\n",
    "            col (int): column of the selected adjacent position\n",
    "        \"\"\"\n",
    "\n",
    "        adjs = [[-1, -1], [-1, 0], [-1, 1], [0, 1], [0, -1], [1, -1], [1, 0], [1, 1]]\n",
    "        adj = random.choice(adjs)\n",
    "        row, col = row + adj[0], col + adj[1]\n",
    "        return row, col\n",
    "\n",
    "    def _is_win(self, color: int, r: int, c: int) -> bool:\n",
    "        \"\"\"check if this player results in a winner\n",
    "\n",
    "        Args:\n",
    "            color (int): of the player\n",
    "            r (int): row of the current play\n",
    "            c (int): column of the current play\n",
    "\n",
    "        Returns:\n",
    "            bool: indicating if there is a winner\n",
    "        \"\"\"\n",
    "\n",
    "        # check if four equal stones are aligned (horizontal, verical or diagonal)\n",
    "        directions = [[0, 1], [1, 0], [1, 1], [1, -1]]\n",
    "\n",
    "        for direct in directions:\n",
    "            count = 0\n",
    "            for offset in range(-3, 4):\n",
    "                if 0 <= r + offset * direct[0] < 9 and 0 <= c + offset * direct[1] < 9:\n",
    "                    if self.board[r + offset * direct[0], c + offset * direct[1]] == color:\n",
    "                        count += 1\n",
    "                        if count == 4:\n",
    "                            return True\n",
    "                    else:\n",
    "                        count = 0\n",
    "\n",
    "        return False\n",
    "\n",
    "    def decode_action(self, action: int) -> List[int]:\n",
    "        \"\"\"decode the action integer into a colum and row value\n",
    "\n",
    "        0 = upper left corner\n",
    "        8 = lower right corner\n",
    "\n",
    "        Args:\n",
    "            action (int): action\n",
    "\n",
    "        Returns:\n",
    "            List[int, int]: a list with the [row, col] values\n",
    "        \"\"\"\n",
    "        action = np.clip(action, 0, self.n_actions)\n",
    "\n",
    "        num_places = BOARD_SIZE * BOARD_SIZE\n",
    "\n",
    "        board_position = action % num_places\n",
    "        energy = action // num_places\n",
    "\n",
    "        col = board_position % BOARD_SIZE\n",
    "        row = board_position // BOARD_SIZE\n",
    "        assert 0 <= col < BOARD_SIZE\n",
    "        assert 0 <= row < BOARD_SIZE\n",
    "        assert 0 <= energy < self.num_bin\n",
    "        return [row, col, energy]\n",
    "\n",
    "    def render(self, render_mode=\"rgb_array\") -> np.ndarray:\n",
    "        \"\"\"Render the board\n",
    "        Print a string that shows the current board, if render_mode == human,\n",
    "        Return the RGB array of a figure which shows the current board.\n",
    "        \"\"\"\n",
    "        board = np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=str)\n",
    "        for ii in range(BOARD_SIZE):\n",
    "            for jj in range(BOARD_SIZE):\n",
    "                if self.board[ii, jj] == 0:\n",
    "                    board[ii, jj] = \"-\"\n",
    "                elif self.board[ii, jj] == 1:\n",
    "                    board[ii, jj] = \"X\"\n",
    "                elif self.board[ii, jj] == 2:\n",
    "                    board[ii, jj] = \"O\"\n",
    "\n",
    "        if render_mode == \"human\":\n",
    "            board = tabulate(board, tablefmt=\"fancy_grid\")\n",
    "            print(board)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        width = height = 400\n",
    "\n",
    "        white = (255, 255, 255)\n",
    "        line_color = (0, 0, 0)\n",
    "        red = (255, 0, 0)\n",
    "\n",
    "        os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "        pg.init()\n",
    "\n",
    "        # Set up the drawing window\n",
    "        if self.screen is None:\n",
    "            self.screen = pg.display.set_mode([width + 272, height + 16])\n",
    "\n",
    "        self.screen.fill(white)\n",
    "        # drawing vertical lines\n",
    "        for i in range(10):\n",
    "            pg.draw.line(self.screen, line_color, (width / BOARD_SIZE * i, 0), (width / BOARD_SIZE * i, height), 2)\n",
    "\n",
    "        # drawing horizontal lines\n",
    "        for i in range(10):\n",
    "            pg.draw.line(self.screen, line_color, (0, height / BOARD_SIZE * i), (width, height / BOARD_SIZE * i), 2)\n",
    "        pg.display.flip()\n",
    "\n",
    "        latest_row, latest_col, latest_enr = -1, -1, 0\n",
    "        if self.latest_action:\n",
    "            latest_row, latest_col, latest_enr = self.decode_action(self.latest_action)\n",
    "\n",
    "        # drawing noughts and crosses\n",
    "        for i in range(BOARD_SIZE):\n",
    "            for j in range(BOARD_SIZE):\n",
    "                color = line_color\n",
    "                if latest_row == i and latest_col == j:\n",
    "                    color = red\n",
    "                if self.board[i, j] == 1:  # Draw crosses\n",
    "                    pg.draw.lines(self.screen, color, True, [(width / BOARD_SIZE * (j + 0.5) - 10,\n",
    "                                                              height / BOARD_SIZE * (i + 0.5) - 10),\n",
    "                                                             (width / BOARD_SIZE * (j + 0.5) + 10,\n",
    "                                                              height / BOARD_SIZE * (i + 0.5) + 10)], 3)\n",
    "                    pg.draw.lines(self.screen, color, True, [(width / BOARD_SIZE * (j + 0.5) - 10,\n",
    "                                                              height / BOARD_SIZE * (i + 0.5) + 10),\n",
    "                                                             (width / BOARD_SIZE * (j + 0.5) + 10,\n",
    "                                                              height / BOARD_SIZE * (i + 0.5) - 10)], 3)\n",
    "                elif self.board[i, j] == 2:  # Draw noughts\n",
    "                    pg.draw.circle(self.screen, color,\n",
    "                                   (width / BOARD_SIZE * (j + 0.5), height / BOARD_SIZE * (i + 0.5)), 12, 3)\n",
    "\n",
    "        # drawing the next energy points of two players\n",
    "        font1 = pg.font.Font(pg.font.get_default_font(), 16)\n",
    "        font2 = pg.font.Font(pg.font.get_default_font(), 14)\n",
    "\n",
    "        latest_player = self.current_player + 1 if self.current_player == 1 else 1\n",
    "        # now print the text\n",
    "        text_surface1 = font1.render('Energy Points:', True, pg.Color('black'))\n",
    "        text_surface2 = font2.render(f'Player 1: {self.info[\"players\"][1][\"energy\"]:.2f}', True, pg.Color('black'))\n",
    "        text_surface3 = font2.render(f'Player 2: {self.info[\"players\"][2][\"energy\"]:.2f}', True, pg.Color('black'))\n",
    "        self.screen.blit(text_surface1, dest=(width + 15, 0))\n",
    "        self.screen.blit(text_surface2, dest=(width + 15, 22))\n",
    "        self.screen.blit(text_surface3, dest=(width + 15, 42))\n",
    "\n",
    "        if latest_col >= 0 and latest_row >= 0:\n",
    "            text_surface4 = font2.render(f'Player {latest_player} used {latest_enr * self.ener_bin_len:.2f} points', True,\n",
    "                                         pg.Color('black'))\n",
    "            self.screen.blit(text_surface4, dest=(width + 15, 72))\n",
    "\n",
    "        board = np.transpose(\n",
    "            np.array(pg.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "        )\n",
    "\n",
    "        return board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Yhocpw-j36C0"
   },
   "outputs": [],
   "source": [
    "def observation_and_action_constraint_splitter(obs):\n",
    "    return obs['state'], obs['legal_moves']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqFsRLWJslkf"
   },
   "source": [
    "## Random play test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qJYsgWM-79vr"
   },
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "    video = open(filename,'rb').read()\n",
    "    b64 = base64.b64encode(video)\n",
    "    tag = '''\n",
    "    <video width=\"480\" height=\"480\" controls>\n",
    "      <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "    </video>'''.format(b64.decode())\n",
    "\n",
    "    return IPython.display.HTML(tag)\n",
    "\n",
    "def create_policy_eval_video(eval_env, policy, filename, fps=2):\n",
    "    py_env = eval_env._envs[0]\n",
    "    tf_env = eval_env\n",
    "    filename = filename + \".mp4\"\n",
    "    with imageio.get_writer(filename, fps=fps) as video:\n",
    "      time_step = tf_env.reset()\n",
    "      video.append_data(py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step, eval_env)\n",
    "        time_step = tf_env.step(action_step.action)\n",
    "        video.append_data(py_env.render())\n",
    "\n",
    "    return embed_mp4(filename)\n",
    "\n",
    "\n",
    "def create_policy_battle_video(eval_env, policy1, policy2, filename, fps=2):\n",
    "    py_env = eval_env._envs[0]\n",
    "    tf_env = eval_env\n",
    "    filename = filename + \".mp4\"\n",
    "    with imageio.get_writer(filename, fps=fps) as video:\n",
    "      time_step = tf_env.reset()\n",
    "      video.append_data(py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy1.action(time_step, eval_env)\n",
    "        time_step = tf_env.step(action_step.action)\n",
    "        video.append_data(py_env.render())\n",
    "        if not time_step.is_last():\n",
    "          action_step = policy2.action(time_step, eval_env)\n",
    "          time_step = tf_env.step(action_step.action)\n",
    "          video.append_data(py_env.render())\n",
    "\n",
    "    return embed_mp4(filename)\n",
    "\n",
    "def create_random_policy(train_env):\n",
    "    return random_tf_policy.RandomTFPolicy(train_env.time_step_spec(), train_env.action_spec(),\n",
    "                                           observation_and_action_constraint_splitter=observation_and_action_constraint_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501.0
    },
    "id": "yNw07pahBY78",
    "outputId": "e3680310-173a-438d-9403-24f092bf6f73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"480\" height=\"480\" controls>\n",
       "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       "    Your browser does not support the video tag.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_env = TicTacToeEnv2()\n",
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "random_policy = create_random_policy(tf_env)\n",
    "create_policy_eval_video(tf_env, random_policy, \"random-agent-part2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPHWdRyT-ND0"
   },
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TgkdEPg_muzV"
   },
   "outputs": [],
   "source": [
    "def create_q_net(train_env):\n",
    "  conv_layer_params = [32, 64, 128]\n",
    "  action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
    "  num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "  # Define a helper function to create Conv layers configured with the right\n",
    "  # activation and kernel initializer.\n",
    "  def conv_layer(num_units):\n",
    "    return tf.keras.layers.Conv2D(\n",
    "                        filters=num_units,\n",
    "                        kernel_size=[3, 3],\n",
    "                        padding=\"same\",\n",
    "                        data_format=\"channels_last\",\n",
    "                        activation=tf.nn.leaky_relu,\n",
    "                        dtype=float)\n",
    "\n",
    "\n",
    "  # QNetwork consists of a sequence of Conv layers followed by a dense layer\n",
    "  # with `num_actions` units to generate one q_value per available action as\n",
    "  # its output.\n",
    "  normalization1 = tf.keras.layers.BatchNormalization()\n",
    "  normalization2 = tf.keras.layers.BatchNormalization()\n",
    "  conv_layers = [conv_layer(num_units) for num_units in conv_layer_params]\n",
    "  action_conv = tf.keras.layers.Conv2D(filters=4,\n",
    "                      kernel_size=[1, 1], padding=\"same\",\n",
    "                      data_format=\"channels_last\")\n",
    "  flatten = tf.keras.layers.Flatten()\n",
    "  q_values_layer = tf.keras.layers.Dense(\n",
    "      num_actions,\n",
    "      activation=None,\n",
    "      kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "          minval=-0.03, maxval=0.03),\n",
    "      bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "  q_net = sequential.Sequential([normalization1] + conv_layers + [action_conv, normalization2, flatten, q_values_layer])\n",
    "  return q_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SHfKpTle0cOC"
   },
   "outputs": [],
   "source": [
    "def create_dqn_agent(train_env):\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "  q_net = create_q_net(train_env)\n",
    "  agent = dqn_agent.DqnAgent(\n",
    "      train_env.time_step_spec(),\n",
    "      train_env.action_spec(),\n",
    "      q_network=q_net,\n",
    "      gamma=gamma,\n",
    "      observation_and_action_constraint_splitter=observation_and_action_constraint_splitter,\n",
    "      optimizer=optimizer,\n",
    "      td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "      train_step_counter=tf.Variable(0))\n",
    "  agent.initialize()\n",
    "  return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GfDHHq84JCYa"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.trajectories import PolicyStep\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PlayPolicy():\n",
    "    def __init__(self, policy):\n",
    "        self.policy = policy\n",
    "\n",
    "    def action(self, act: int, env=None):\n",
    "        action_step = self.policy.action(act)\n",
    "        if env:\n",
    "            # when the board is empty, choose the center position.\n",
    "            py_env = env._envs[0]\n",
    "            if np.sum(py_env.board) == 0:\n",
    "                return PolicyStep(action=tf.convert_to_tensor(np.array([40])))\n",
    "            elif np.sum(py_env.board) > 6:\n",
    "                current_player = py_env.current_player\n",
    "                opponent = current_player + 1 if current_player == 1 else 1\n",
    "                occupied_positions = py_env.info['Occupied']\n",
    "                for act in range(81):\n",
    "                    if act not in occupied_positions and self.drop_here_will_win(py_env, act, current_player):\n",
    "                        return PolicyStep(action=tf.convert_to_tensor(np.array([act + (py_env.num_bin - 1) * 81])))\n",
    "                for act in range(81):\n",
    "                    if act not in occupied_positions and self.drop_here_will_win(py_env, act, opponent):\n",
    "                        return PolicyStep(action=tf.convert_to_tensor(np.array([act + (py_env.num_bin - 1) * 81])))\n",
    "        return action_step\n",
    "\n",
    "    def drop_here_will_win(self, py_env, action, color):\n",
    "        # check if four equal stones are aligned (horizontal, vertical or diagonal)\n",
    "        directions = [[0, 1], [1, 0], [1, 1], [1, -1]]\n",
    "\n",
    "        current_board = copy.deepcopy(py_env.board)\n",
    "        r, c, _ = py_env.decode_action(action)\n",
    "        current_board[r, c] = color\n",
    "\n",
    "        for direct in directions:\n",
    "            count = 0\n",
    "            for offset in range(-3, 4):\n",
    "                if 0 <= r + offset * direct[0] < 9 and 0 <= c + offset * direct[1] < 9:\n",
    "                    if current_board[r + offset * direct[0], c + offset * direct[1]] == color:\n",
    "                        count += 1\n",
    "                        if count == 4:\n",
    "                            return True\n",
    "                    else:\n",
    "                        count = 0\n",
    "\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaVnWWX4xpa5"
   },
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N8vRFWNgx-tj"
   },
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "def compute_avg_return_battle(environment, policy1, policy2, num_episodes=10):\n",
    "\n",
    "  total_return_1 = 0.0\n",
    "  total_return_2 = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "    episode_return_1 = 0.0\n",
    "    episode_return_2 = 0.0\n",
    "    time_step = environment.reset()\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy1.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return_1 += time_step.reward\n",
    "      if not time_step.is_last():\n",
    "        action_step = policy2.action(time_step)\n",
    "        time_step = environment.step(action_step.action)\n",
    "        episode_return_2 += time_step.reward\n",
    "    total_return_1 += episode_return_1\n",
    "    total_return_2 += episode_return_2\n",
    "\n",
    "  avg_return_1 = total_return_1 / num_episodes\n",
    "  avg_return_2 = total_return_2 / num_episodes\n",
    "  return [avg_return_1.numpy()[0], avg_return_2.numpy()[0]]\n",
    "\n",
    "def compute_avg_win_battle(environment, policy1, policy2, num_episodes=10):\n",
    "\n",
    "  total_return_1 = 0.0\n",
    "  total_return_2 = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "    time_step = environment.reset()\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy1.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      if not time_step.is_last():\n",
    "        action_step = policy2.action(time_step)\n",
    "        time_step = environment.step(action_step.action)\n",
    "    if environment._envs[0].get_result() == 1:\n",
    "        total_return_1 += 1\n",
    "    elif environment._envs[0].get_result() == 2:\n",
    "        total_return_2 += 1\n",
    "\n",
    "  avg_return_1 = total_return_1 / num_episodes\n",
    "  avg_return_2 = total_return_2 / num_episodes\n",
    "  return [avg_return_1, avg_return_2]\n",
    "\n",
    "def create_zip_file(dirname, base_filename):\n",
    "  return shutil.make_archive(base_filename, 'zip', dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBEXcoMjy7xO"
   },
   "source": [
    "## Collect training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CMVmKJF1y_Lt"
   },
   "outputs": [],
   "source": [
    "def collect_episode(environment, agent1, agent2, replay_buffer):\n",
    "    time_step = environment.reset()\n",
    "    trajs_1, trajs_2 = [], []\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        action_step = agent1.collect_policy.action(time_step)\n",
    "        next_time_step = environment.step(action_step.action)\n",
    "        traj1 = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "        trajs_1.append(traj1)\n",
    "        time_step = next_time_step\n",
    "\n",
    "        if not time_step.is_last():\n",
    "            action_step = agent2.collect_policy.action(time_step)\n",
    "            next_time_step = environment.step(action_step.action)\n",
    "            traj2 = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "            trajs_2.append(traj2)\n",
    "            time_step = next_time_step\n",
    "\n",
    "    change_flag = False\n",
    "    # Modify the reward of each step according to the opponent's next step\n",
    "    if len(trajs_1) == len(trajs_2):  # Player 2 won\n",
    "        for i in range(len(trajs_1) - 1):\n",
    "            trajs_1[i] = trajs_1[i].replace(reward=trajs_1[i].reward - trajs_2[i].reward)\n",
    "            trajs_2[i] = trajs_2[i].replace(reward=trajs_2[i].reward - trajs_1[i + 1].reward)\n",
    "        trajs_1[-1] = trajs_1[-1].replace(reward=trajs_1[-1].reward - trajs_2[-1].reward)\n",
    "    else:  # Player 1 won\n",
    "        change_flag = True\n",
    "        for i in range(len(trajs_1) - 1):\n",
    "            trajs_1[i] = trajs_1[i].replace(reward=trajs_1[i].reward - trajs_2[i].reward)\n",
    "            trajs_2[i] = trajs_2[i].replace(reward=trajs_2[i].reward - trajs_1[i + 1].reward)\n",
    "\n",
    "    for i in range(len(trajs_1)):\n",
    "        replay_buffer.add_batch(trajs_1[i])\n",
    "    for i in range(len(trajs_2)):\n",
    "        replay_buffer.add_batch(trajs_2[i])\n",
    "\n",
    "    # If the first player wins, then change the order in the next game.\n",
    "    return change_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRVMc8V8zxj0"
   },
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6_1qWkmKz0Ke"
   },
   "outputs": [],
   "source": [
    "def train_game_agent():\n",
    "    train_py_env = TicTacToeEnv2(train=True)\n",
    "    eval_py_env = TicTacToeEnv2()\n",
    "\n",
    "    train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "    eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "    agent1 = create_dqn_agent(train_env)\n",
    "    agent2 = create_dqn_agent(train_env)\n",
    "\n",
    "    play_policy = PlayPolicy(agent1.policy)\n",
    "    random_policy = create_random_policy(train_env)\n",
    "\n",
    "    replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "        data_spec=agent1.collect_data_spec,\n",
    "        batch_size=train_env.batch_size,\n",
    "        max_length=replay_buffer_max_length)\n",
    "\n",
    "    for _ in range(initial_collect_episodes):\n",
    "        collect_episode(train_env, agent1, agent2, replay_buffer)\n",
    "\n",
    "    dataset = replay_buffer.as_dataset(\n",
    "        num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "        num_steps=n_step_update + 1).prefetch(3)\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    policy_dir = os.path.join(tempdir, 'play_policy_part2')\n",
    "    tf_policy_saver = policy_saver.PolicySaver(play_policy.policy)\n",
    "\n",
    "    # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "    agent1.train = common.function(agent1.train)\n",
    "    agent2.train = common.function(agent2.train)\n",
    "\n",
    "    # Reset the train step.\n",
    "    agent1.train_step_counter.assign(0)\n",
    "    agent2.train_step_counter.assign(0)\n",
    "    policy_win_rate = compute_avg_win_battle(eval_env, play_policy, random_policy, num_eval_episodes)[0]\n",
    "    print('Before training: 1_win = {0}'.format(policy_win_rate))\n",
    "\n",
    "    bst = 0\n",
    "\n",
    "    # Reset the environment.\n",
    "    train_env.reset()\n",
    "\n",
    "    x, y, change_flag = agent1, agent2, False\n",
    "    for idx in range(num_iterations):\n",
    "        # Collect a few episodes using collect_policy and store the transitions to the replay buffer.\n",
    "        for _ in range(collect_episodes_per_iteration):\n",
    "            if change_flag:\n",
    "                x, y = y, x\n",
    "            change_flag = collect_episode(train_env, x, y, replay_buffer)\n",
    "\n",
    "        # Sample a batch of data from the buffer and update the agent's network.\n",
    "        experience, unused_info = next(iterator)\n",
    "        train_loss1 = agent1.train(experience).loss\n",
    "        experience, unused_info = next(iterator)\n",
    "        agent2.train(experience)\n",
    "\n",
    "        step = agent1.train_step_counter.numpy()\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "            print('step = {0}: loss1 = {1}'.format(step, train_loss1))\n",
    "\n",
    "        if step % eval_interval == 0:\n",
    "            policy_win_rate1 = compute_avg_win_battle(eval_env, play_policy, random_policy, num_eval_episodes)[0]\n",
    "            policy_win_rate2 = compute_avg_win_battle(eval_env, random_policy, play_policy, num_eval_episodes)[1]\n",
    "            print('Evaluation (step = {0}): offense_win = {1}, defense_win = {2}'.format(step,\n",
    "                                                                                         policy_win_rate1,\n",
    "                                                                                         policy_win_rate2,\n",
    "                                                                                         ))\n",
    "            policy_win_rate = (policy_win_rate1 + policy_win_rate2) / 2\n",
    "            if policy_win_rate >= bst:\n",
    "                bst = policy_win_rate\n",
    "                tf_policy_saver.save(policy_dir)\n",
    "                # create_zip_file(policy_dir, os.path.join(tempdir, 'exported_policy_part2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8CTaM4JuW1n",
    "outputId": "7454353c-f52d-4b62-e2ac-9d2dea31a171"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tf_agents/replay_buffers/tf_uniform_replay_buffer.py:364: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: 1_win = 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5: loss1 = 0.5202822685241699\n",
      "step = 10: loss1 = 0.3848797082901001\n",
      "step = 15: loss1 = 0.27704811096191406\n",
      "step = 20: loss1 = 0.30223172903060913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`0/step_type` is not a valid tf.function parameter name. Sanitizing to `arg_0_step_type`.\n",
      "WARNING:absl:`0/reward` is not a valid tf.function parameter name. Sanitizing to `arg_0_reward`.\n",
      "WARNING:absl:`0/discount` is not a valid tf.function parameter name. Sanitizing to `arg_0_discount`.\n",
      "WARNING:absl:`0/observation/legal_moves` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_legal_moves`.\n",
      "WARNING:absl:`0/observation/state` is not a valid tf.function parameter name. Sanitizing to `arg_0_observation_state`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation (step = 20): offense_win = 0.46, defense_win = 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 25: loss1 = 0.26059049367904663\n",
      "step = 30: loss1 = 0.31859999895095825\n",
      "step = 35: loss1 = 0.43355485796928406\n",
      "step = 40: loss1 = 0.2564083933830261\n",
      "Evaluation (step = 40): offense_win = 0.76, defense_win = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 45: loss1 = 0.4993528425693512\n",
      "step = 50: loss1 = 0.5963534116744995\n",
      "step = 55: loss1 = 0.6059081554412842\n",
      "step = 60: loss1 = 0.24642178416252136\n",
      "Evaluation (step = 60): offense_win = 0.72, defense_win = 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 65: loss1 = 0.23570804297924042\n",
      "step = 70: loss1 = 0.6900163292884827\n",
      "step = 75: loss1 = 0.2818489670753479\n",
      "step = 80: loss1 = 0.26019197702407837\n",
      "Evaluation (step = 80): offense_win = 0.58, defense_win = 0.6\n",
      "step = 85: loss1 = 0.797818660736084\n",
      "step = 90: loss1 = 0.2860153913497925\n",
      "step = 95: loss1 = 0.24205900728702545\n",
      "step = 100: loss1 = 0.3508000373840332\n",
      "Evaluation (step = 100): offense_win = 0.74, defense_win = 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 105: loss1 = 0.407173216342926\n",
      "step = 110: loss1 = 0.2522944211959839\n",
      "step = 115: loss1 = 0.5507755279541016\n",
      "step = 120: loss1 = 0.17751184105873108\n",
      "Evaluation (step = 120): offense_win = 0.72, defense_win = 0.66\n",
      "step = 125: loss1 = 0.28291386365890503\n",
      "step = 130: loss1 = 0.3967795670032501\n",
      "step = 135: loss1 = 0.5218859314918518\n",
      "step = 140: loss1 = 0.1779574453830719\n",
      "Evaluation (step = 140): offense_win = 0.66, defense_win = 0.64\n",
      "step = 145: loss1 = 0.5307129621505737\n",
      "step = 150: loss1 = 0.3630845844745636\n",
      "step = 155: loss1 = 0.2161044180393219\n",
      "step = 160: loss1 = 0.21886155009269714\n",
      "Evaluation (step = 160): offense_win = 0.78, defense_win = 0.66\n",
      "step = 165: loss1 = 0.47074881196022034\n",
      "step = 170: loss1 = 0.5489680767059326\n",
      "step = 175: loss1 = 0.45764902234077454\n",
      "step = 180: loss1 = 0.21019577980041504\n",
      "Evaluation (step = 180): offense_win = 0.72, defense_win = 0.68\n",
      "step = 185: loss1 = 0.17245429754257202\n",
      "step = 190: loss1 = 0.36123597621917725\n",
      "step = 195: loss1 = 0.38510388135910034\n",
      "step = 200: loss1 = 0.3231344223022461\n",
      "Evaluation (step = 200): offense_win = 0.68, defense_win = 0.66\n",
      "step = 205: loss1 = 0.37828677892684937\n",
      "step = 210: loss1 = 0.48680078983306885\n",
      "step = 215: loss1 = 0.4072941243648529\n",
      "step = 220: loss1 = 0.27480119466781616\n",
      "Evaluation (step = 220): offense_win = 0.76, defense_win = 0.56\n",
      "step = 225: loss1 = 0.20972971618175507\n",
      "step = 230: loss1 = 0.44471675157546997\n",
      "step = 235: loss1 = 0.26253169775009155\n",
      "step = 240: loss1 = 0.4626106917858124\n",
      "Evaluation (step = 240): offense_win = 0.76, defense_win = 0.62\n",
      "step = 245: loss1 = 0.5696115493774414\n",
      "step = 250: loss1 = 0.3701896667480469\n",
      "step = 255: loss1 = 0.5020799040794373\n",
      "step = 260: loss1 = 0.21824486553668976\n",
      "Evaluation (step = 260): offense_win = 0.72, defense_win = 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 265: loss1 = 0.314255952835083\n",
      "step = 270: loss1 = 0.3546740412712097\n",
      "step = 275: loss1 = 0.5081530809402466\n",
      "step = 280: loss1 = 0.2982848286628723\n",
      "Evaluation (step = 280): offense_win = 0.72, defense_win = 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 285: loss1 = 0.3077732026576996\n",
      "step = 290: loss1 = 0.48336368799209595\n",
      "step = 295: loss1 = 0.36547625064849854\n",
      "step = 300: loss1 = 0.35242414474487305\n",
      "Evaluation (step = 300): offense_win = 0.68, defense_win = 0.58\n",
      "step = 305: loss1 = 0.3302222490310669\n",
      "step = 310: loss1 = 0.34526312351226807\n",
      "step = 315: loss1 = 0.4362480342388153\n",
      "step = 320: loss1 = 0.2864343523979187\n",
      "Evaluation (step = 320): offense_win = 0.64, defense_win = 0.68\n",
      "step = 325: loss1 = 0.39909613132476807\n",
      "step = 330: loss1 = 0.5082756280899048\n",
      "step = 335: loss1 = 0.5163301825523376\n",
      "step = 340: loss1 = 0.23449759185314178\n",
      "Evaluation (step = 340): offense_win = 0.76, defense_win = 0.68\n",
      "step = 345: loss1 = 0.7989844083786011\n",
      "step = 350: loss1 = 0.2730916738510132\n",
      "step = 355: loss1 = 0.3853558897972107\n",
      "step = 360: loss1 = 0.5267512202262878\n",
      "Evaluation (step = 360): offense_win = 0.62, defense_win = 0.66\n",
      "step = 365: loss1 = 0.36465027928352356\n",
      "step = 370: loss1 = 0.5887670516967773\n",
      "step = 375: loss1 = 0.5837392807006836\n",
      "step = 380: loss1 = 0.6001040935516357\n",
      "Evaluation (step = 380): offense_win = 0.76, defense_win = 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 385: loss1 = 0.6099482774734497\n",
      "step = 390: loss1 = 0.6423933506011963\n",
      "step = 395: loss1 = 0.6420032978057861\n",
      "step = 400: loss1 = 0.1340738832950592\n",
      "Evaluation (step = 400): offense_win = 0.74, defense_win = 0.66\n",
      "step = 405: loss1 = 0.589032769203186\n",
      "step = 410: loss1 = 0.36881357431411743\n",
      "step = 415: loss1 = 0.28935325145721436\n",
      "step = 420: loss1 = 0.28610315918922424\n",
      "Evaluation (step = 420): offense_win = 0.86, defense_win = 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/nested_structure_coder.py:458: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 425: loss1 = 0.39218997955322266\n",
      "step = 430: loss1 = 0.41472870111465454\n",
      "step = 435: loss1 = 0.30489248037338257\n",
      "step = 440: loss1 = 0.23932865262031555\n"
     ]
    }
   ],
   "source": [
    "train_game_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euOj19B0B1ky"
   },
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_wl7mg6ugoW"
   },
   "outputs": [],
   "source": [
    "eval_py_env = TicTacToeEnv2()\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "random_policy = random_policy = create_random_policy(eval_env)\n",
    "policy_dir = os.path.join(tempdir, 'play_policy_part2')\n",
    "\n",
    "play_policy = PlayPolicy(tf.saved_model.load(policy_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_qJ0PoMxVk2"
   },
   "source": [
    "#### Trained agent (X) v.s. Random policy (O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSRWvH6Udnd1"
   },
   "outputs": [],
   "source": [
    "create_policy_battle_video(eval_env, play_policy, random_policy, 'trained-agent-2-with-random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTsrQIhi1elu"
   },
   "source": [
    "#### Random policy (O) v.s. Trained agent (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXOhayRA1kr9"
   },
   "outputs": [],
   "source": [
    "create_policy_battle_video(eval_env, random_policy, play_policy, 'random-with-trained-agent-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJvOotJdxfeE"
   },
   "source": [
    "#### Trained agent (X) v.s. Trained agent (O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9drEVaBPxSAz"
   },
   "outputs": [],
   "source": [
    "create_policy_battle_video(eval_env, play_policy, play_policy, 'trained-agent-2-self-battle')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPPJ/beWr6g33UDqTE07hAA",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
