{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stevenn9981/tic_tac_toe/blob/master/tic_tac_toe_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEy_PMnnf-Og"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdG6QronfqnR",
        "outputId": "ed2ba847-ba27-4c27-c736-a39e75b9d2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/110 kB 13%] [Connecting to cloud.\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 25.8 kB/110 kB 23%] [Connected to cloud.r\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r0% [3 InRelease 12.7 kB/119 kB 11%] [1 InRelease 43.1 kB/110 kB 39%] [Waiting f\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 229 kB in 2s (122 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-6).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Requirement already satisfied: imageio==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.0) (9.4.0)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: tensorflow-probability~=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.22.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: dm-reverb~=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.13.0)\n",
            "Requirement already satisfied: tensorflow~=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.14.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.13.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.13.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (1.59.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-agents[reverb]) (2.14.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.14.0->tf-agents[reverb]) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker->dm-reverb~=0.13.0->tf-agents[reverb]) (5.9.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-agents[reverb]) (3.2.2)\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.10/dist-packages (2.0.9)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents[reverb]\n",
        "!pip install pyglet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "h-vtSiPUgOOU"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "import reverb\n",
        "import random\n",
        "import os\n",
        "\n",
        "import pygame as pg\n",
        "from pygame import gfxdraw\n",
        "from pygame.locals import *\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MsV4e7iqg10s",
        "outputId": "ec41d095-03ad-47e7-aaa2-5ae489c04b8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.14.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tf.version.VERSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWwU8Wp7g2_X"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "reKJx_ybg7_L"
      },
      "outputs": [],
      "source": [
        "num_iterations = 100000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 256  # @param {type:\"integer\"}\n",
        "learning_rate = 3e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "BOARD_SIZE = 9 # @param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOBVDKmMIcyJ"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aq7Q2oxyIhS8"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import math\n",
        "from tabulate import tabulate\n",
        "\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "class TicTacToeEnv1(gym.Env):\n",
        "    \"\"\"\n",
        "    Implementation of a TicTacToe Environment based on OpenAI Gym standards\n",
        "    This class is modified from https://github.com/MauroLuzzatto/OpenAI-Gym-TicTacToe-Environment\n",
        "    I modified that to follow the instructions of Question 1.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode='rgb_array') -> None:\n",
        "        \"\"\"This class contains a TicTacToe environment for OpenAI Gym\n",
        "\n",
        "        Args:\n",
        "            small (int): small reward for each move (punishment)\n",
        "            large (int): large reward for game winner\n",
        "        \"\"\"\n",
        "        n_actions = BOARD_SIZE * BOARD_SIZE         # 9 * 9 grids to drop\n",
        "        self.action_space = gym.spaces.Discrete(n_actions)\n",
        "        # state: 9 * 9 * 2: the first 9 * 9 layer is the opponent's play history and the second 9 * 9 layer is ours.\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(BOARD_SIZE, BOARD_SIZE, 2), dtype=float)\n",
        "        self.render_mode = mode\n",
        "        self.colors = [1, 2]\n",
        "        self.screen = None\n",
        "        self.fields_per_side = int(math.sqrt(n_actions))\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self) -> Tuple[np.ndarray, dict]:\n",
        "        \"\"\"\n",
        "        reset the board game and state\n",
        "        \"\"\"\n",
        "        self.board: np.ndarray = np.zeros(\n",
        "            (self.fields_per_side, self.fields_per_side), dtype=int\n",
        "        )\n",
        "        self.current_player = 1\n",
        "        self.info = {\"players\": {1: {\"actions\": []}, 2: {\"actions\": []}}, \"Occupied\": set()}\n",
        "\n",
        "        if self.render_mode == 'human':\n",
        "            self.render(self.render_mode)\n",
        "        return self.decompose_board_to_state()\n",
        "\n",
        "    def decompose_board_to_state(self):\n",
        "        \"\"\"\n",
        "        Our state is a 9x9x2 matrix.\n",
        "        The first layer is the opponent's play history, 0 means no stone, 1 means stones placed by the opponent.\n",
        "        The second layer is the current player's history, 0 means no stone, 1 means stones placed by the current player.\n",
        "        \"\"\"\n",
        "        opponent = 2 if self.current_player == 1 else 1\n",
        "        o_plays = (self.board == opponent) * 1\n",
        "        c_plays = (self.board == self.current_player) * 1\n",
        "        return np.stack([o_plays, c_plays], axis=2)\n",
        "\n",
        "\n",
        "    def step(self, action: int) -> Tuple[np.ndarray, int, bool, dict]:\n",
        "        \"\"\"step function of the tictactoeEnv1\n",
        "\n",
        "        Args:\n",
        "          action (int): integer between 0-80, each representing a field on the board\n",
        "\n",
        "        Returns:\n",
        "          state (np.array): state of 2 players' history, 0 means no stone, 1 means stones placed by the corresponding player (shape: 9x9x2).\n",
        "          reward (int): reward of the currrent step\n",
        "          done (boolean): true, if the game is finished\n",
        "          (dict): empty dict for future game related information\n",
        "        \"\"\"\n",
        "        if not self.action_space.contains(action):\n",
        "            raise ValueError(f\"action '{action}' is not in action_space\")\n",
        "\n",
        "        reward = -0.1  # assign (negative) reward for every move done\n",
        "        (row, col) = self.decode_action(action)\n",
        "\n",
        "        # If the agent/player does not choose an empty square, randomly select an empty one.\n",
        "        if self.board[row, col] != 0:\n",
        "            action = random.choice(list(set(range(BOARD_SIZE * BOARD_SIZE)) - self.info[\"Occupied\"]))\n",
        "            (row, col) = self.decode_action(action)\n",
        "            reward -= 0.3 # assign a negative reward if the play out position is not empty\n",
        "\n",
        "\n",
        "        # randomly select an adjacent position with probability 1/16\n",
        "        if random.random() < 0.5:\n",
        "            adjs = [[-1, -1], [-1, 0], [-1, 1], [0, 1], [0, -1], [1, -1], [1, 0], [1, 1]]\n",
        "            adj = random.choice(adjs)\n",
        "            row, col = row + adj[0], col + adj[1]\n",
        "\n",
        "        if 0 <= row < BOARD_SIZE and 0 <= col < BOARD_SIZE and self.board[row, col] == 0:\n",
        "            self.board[row, col] = self.current_player  # postion the token on the field\n",
        "            win = self._is_win(self.current_player, row, col)\n",
        "\n",
        "            action = row * BOARD_SIZE + col\n",
        "            self.info[\"players\"][self.current_player][\"actions\"].append(action)\n",
        "            self.info[\"Occupied\"].add(action)\n",
        "        else:\n",
        "            win = False\n",
        "\n",
        "        if win:\n",
        "            reward += 3\n",
        "\n",
        "        done = (win or len(self.info[\"Occupied\"]) == BOARD_SIZE * BOARD_SIZE)\n",
        "        self.current_player = self.current_player + 1 if self.current_player == 1 else 1\n",
        "        state = self.decompose_board_to_state()\n",
        "        return state, reward, done, self.info\n",
        "\n",
        "    def _is_win(self, color: int, r: int, c: int) -> bool:\n",
        "        \"\"\"check if this player results in a winner\n",
        "\n",
        "        Args:\n",
        "            color (int): of the player\n",
        "            r (int): row of the current play\n",
        "            c (int): column of the current play\n",
        "\n",
        "        Returns:\n",
        "            bool: indicating if there is a winner\n",
        "        \"\"\"\n",
        "\n",
        "        # check if four equal stones are aligned (horizontal, verical or diagonal)\n",
        "        directions = [[0, 1], [1, 0], [1, 1], [1, -1]]\n",
        "\n",
        "        for direct in directions:\n",
        "            count = 0\n",
        "            for offset in range(-3, 4):\n",
        "                if 0 <= r + offset * direct[0] < 9 and 0 <= c + offset * direct[1] < 9:\n",
        "                    if self.board[r + offset * direct[0], c + offset * direct[1]] == color:\n",
        "                        count += 1\n",
        "                        if count == 4:\n",
        "                            return True\n",
        "                    else:\n",
        "                        count = 0\n",
        "\n",
        "        return False\n",
        "\n",
        "    def decode_action(self, action: int) -> List[int]:\n",
        "        \"\"\"decode the action integer into a colum and row value\n",
        "\n",
        "        0 = upper left corner\n",
        "        8 = lower right corner\n",
        "\n",
        "        Args:\n",
        "            action (int): action\n",
        "\n",
        "        Returns:\n",
        "            List[int, int]: a list with the [row, col] values\n",
        "        \"\"\"\n",
        "        col = action % BOARD_SIZE\n",
        "        row = action // BOARD_SIZE\n",
        "        assert 0 <= col < BOARD_SIZE\n",
        "        return [row, col]\n",
        "\n",
        "    def render(self, mode=\"human\") -> None:\n",
        "        \"\"\"render the board\n",
        "\n",
        "        The following charachters are used to represent the fields,\n",
        "            '-' no stone\n",
        "            'O' for player 0\n",
        "            'X' for player 1\n",
        "\n",
        "        An example for a 3x3 game board:\n",
        "            ╒═══╤═══╤═══╕\n",
        "            │ O │ - │ - │\n",
        "            ├───┼───┼───┤\n",
        "            │ - │ X │ - │\n",
        "            ├───┼───┼───┤\n",
        "            │ - │ - │ - │\n",
        "            ╘═══╧═══╧═══╛\n",
        "        \"\"\"\n",
        "        board = np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=str)\n",
        "        for ii in range(BOARD_SIZE):\n",
        "            for jj in range(BOARD_SIZE):\n",
        "                if self.board[ii, jj] == 0:\n",
        "                    board[ii, jj] = \"-\"\n",
        "                elif self.board[ii, jj] == 1:\n",
        "                    board[ii, jj] = \"X\"\n",
        "                elif self.board[ii, jj] == 2:\n",
        "                    board[ii, jj] = \"O\"\n",
        "\n",
        "        if mode == \"human\":\n",
        "            board = tabulate(board, tablefmt=\"fancy_grid\")\n",
        "            print(board)\n",
        "            print(\"\\n\")\n",
        "\n",
        "\n",
        "        width = height = 400\n",
        "\n",
        "        white = (255, 255, 255)\n",
        "        line_color = (0, 0, 0)\n",
        "\n",
        "        os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "        pg.init()\n",
        "\n",
        "        # Set up the drawing window\n",
        "        if self.screen is None:\n",
        "          self.screen = pg.display.set_mode([width + 16, height + 16])\n",
        "\n",
        "        self.screen.fill(white)\n",
        "        # drawing vertical lines\n",
        "        for i in range(10):\n",
        "          pg.draw.line(self.screen, line_color, (width / BOARD_SIZE * i, 0), (width / BOARD_SIZE * i, height), 2)\n",
        "\n",
        "        # drawing horizontal lines\n",
        "        for i in range(10):\n",
        "          pg.draw.line(self.screen, line_color, (0, height / BOARD_SIZE * i), (width, height / BOARD_SIZE * i), 2)\n",
        "        pg.display.flip()\n",
        "\n",
        "        # drawing noughts and crosses\n",
        "        for i in range(BOARD_SIZE):\n",
        "          for j in range(BOARD_SIZE):\n",
        "            if self.board[i, j] == 1: # Draw crosses\n",
        "              pg.draw.lines(self.screen, line_color, True, [(width / BOARD_SIZE * (j + 0.5) - 10,\n",
        "                                                        height / BOARD_SIZE * (i + 0.5) - 10),\n",
        "                                                      (width / BOARD_SIZE * (j + 0.5) + 10,\n",
        "                                                        height / BOARD_SIZE * (i + 0.5) + 10)], 3)\n",
        "              pg.draw.lines(self.screen, line_color, True, [(width / BOARD_SIZE * (j + 0.5) - 10,\n",
        "                                                        height / BOARD_SIZE * (i + 0.5) + 10),\n",
        "                                                        (width / BOARD_SIZE * (j + 0.5) + 10,\n",
        "                                                          height / BOARD_SIZE * (i + 0.5) - 10)], 3)\n",
        "            elif self.board[i, j] == 2: # Draw noughts\n",
        "              pg.draw.circle(self.screen, line_color, (width / BOARD_SIZE * (j + 0.5), height / BOARD_SIZE * (i + 0.5)), 12, 3)\n",
        "\n",
        "        board = np.transpose(\n",
        "                np.array(pg.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
        "            )\n",
        "\n",
        "        return board"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqFsRLWJslkf"
      },
      "source": [
        "## Random play test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qJYsgWM-79vr"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "    video = open(filename,'rb').read()\n",
        "    b64 = base64.b64encode(video)\n",
        "    tag = '''\n",
        "    <video width=\"480\" height=\"480\" controls>\n",
        "      <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "    Your browser does not support the video tag.\n",
        "    </video>'''.format(b64.decode())\n",
        "\n",
        "    return IPython.display.HTML(tag)\n",
        "\n",
        "def create_policy_eval_video(policy, filename, fps=2):\n",
        "    filename = filename + \".mp4\"\n",
        "    with imageio.get_writer(filename, fps=fps) as video:\n",
        "      time_step = tf_env.reset()\n",
        "      video.append_data(py_env.render())\n",
        "      while not time_step.is_last():\n",
        "        action_step = policy.action(time_step)\n",
        "        time_step = tf_env.step(action_step.action)\n",
        "        video.append_data(py_env.render())\n",
        "\n",
        "    return embed_mp4(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uU1h9wSWa7Lh"
      },
      "outputs": [],
      "source": [
        "py_env = suite_gym.wrap_env(TicTacToeEnv1())\n",
        "tf_env = tf_py_environment.TFPyEnvironment(py_env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "yNw07pahBY78",
        "outputId": "9348a3d8-405a-4892-aa3b-5850a57fe854"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <video width=\"480\" height=\"480\" controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "    Your browser does not support the video tag.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "random_policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(), tf_env.action_spec())\n",
        "create_policy_eval_video(random_policy, \"random-agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPHWdRyT-ND0"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MnqVY5icuPi4"
      },
      "outputs": [],
      "source": [
        "train_py_env = suite_gym.wrap_env(TicTacToeEnv1())\n",
        "eval_py_env = suite_gym.wrap_env(TicTacToeEnv1())\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TgkdEPg_muzV"
      },
      "outputs": [],
      "source": [
        "conv_layer_params = (8, 16)\n",
        "action_tensor_spec = tensor_spec.from_spec(tf_env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "# Define a helper function to create Conv layers configured with the right\n",
        "# activation and kernel initializer.\n",
        "def conv_layer(num_units):\n",
        "  return tf.keras.layers.Conv2D(filters=num_units,\n",
        "                      kernel_size=[3, 3],\n",
        "                      padding=\"same\",\n",
        "                      data_format=\"channels_last\",\n",
        "                      activation=tf.nn.leaky_relu)\n",
        "\n",
        "\n",
        "# QNetwork consists of a sequence of Conv layers followed by a dense layer\n",
        "# with `num_actions` units to generate one q_value per available action as\n",
        "# its output.\n",
        "conv_layers = [conv_layer(num_units) for num_units in conv_layer_params]\n",
        "action_conv = tf.keras.layers.Conv2D(filters=4,\n",
        "                    kernel_size=[1, 1], padding=\"same\",\n",
        "                    data_format=\"channels_last\",\n",
        "                    activation=tf.nn.leaky_relu)\n",
        "flatten = tf.keras.layers.Flatten()\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = sequential.Sequential(conv_layers + [action_conv, flatten, q_values_layer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lg5emNEam75J"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaVnWWX4xpa5"
      },
      "source": [
        "## Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uGU0pGS4xsjc"
      },
      "outputs": [],
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy\n",
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(), train_env.action_spec())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "N8vRFWNgx-tj"
      },
      "outputs": [],
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]\n",
        "\n",
        "\n",
        "# See also the metrics module for standard implementations of different metrics.\n",
        "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlCXIdRVyAAu",
        "outputId": "3430f46b-ac51-4d26-ae44-da0e84f42911"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-4.500001"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "compute_avg_return(eval_env, agent.policy, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBEXcoMjy7xO"
      },
      "source": [
        "## Replay Buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "CMVmKJF1y_Lt"
      },
      "outputs": [],
      "source": [
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(\n",
        "      agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "    replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_max_length,\n",
        "    sampler=reverb.selectors.Uniform(),\n",
        "    remover=reverb.selectors.Fifo(),\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "    signature=replay_buffer_signature)\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name=table_name,\n",
        "    sequence_length=2,\n",
        "    local_server=reverb_server)\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "  replay_buffer.py_client,\n",
        "  table_name,\n",
        "  sequence_length=2)\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "iterator = iter(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RomK5WUjtYbO",
        "outputId": "b37dbf54-a4f1-40fd-dd69-849ad94c8fd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TimeStep(\n",
              " {'discount': array(1., dtype=float32),\n",
              "  'observation': array([[[0., 1.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 1.]],\n",
              " \n",
              "        [[1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.]],\n",
              " \n",
              "        [[1., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 0.]],\n",
              " \n",
              "        [[0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 1.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 1.]],\n",
              " \n",
              "        [[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.]],\n",
              " \n",
              "        [[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]],\n",
              " \n",
              "        [[0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [1., 0.]],\n",
              " \n",
              "        [[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]],\n",
              " \n",
              "        [[0., 1.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]]]),\n",
              "  'reward': array(-0.1, dtype=float32),\n",
              "  'step_type': array(1, dtype=int32)}),\n",
              " ())"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "py_driver.PyDriver(\n",
        "    train_py_env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      random_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps).run(train_py_env.reset())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRVMc8V8zxj0"
      },
      "source": [
        "## Train the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_1qWkmKz0Ke",
        "outputId": "ef70188d-a6d1-4b95-fb51-42927618cc79"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 10593062912.0\n",
            "step = 400: loss = 32273848074240.0\n",
            "step = 600: loss = 456847685320704.0\n",
            "step = 800: loss = 3078535921008640.0\n",
            "step = 1000: loss = 2.3341897418276864e+16\n",
            "step = 1000: Average Return = -16.469989776611328\n",
            "step = 1200: loss = 8.96345673081815e+16\n",
            "step = 1400: loss = 1.5865732886482125e+17\n",
            "step = 1600: loss = 2.3301286784506266e+17\n",
            "step = 1800: loss = 1.2616498730154066e+18\n",
            "step = 2000: loss = 1.6537085065675407e+18\n",
            "step = 2000: Average Return = -16.529991149902344\n",
            "step = 2200: loss = 5.282996141300908e+18\n",
            "step = 2400: loss = 3.65181236737894e+18\n",
            "step = 2600: loss = 1.3726242688016056e+19\n",
            "step = 2800: loss = 8.788004464918266e+18\n",
            "step = 3000: loss = 7.062004855530848e+18\n",
            "step = 3000: Average Return = -13.289993286132812\n",
            "step = 3200: loss = 2.7679875375772467e+19\n",
            "step = 3400: loss = 5.1925492152884265e+19\n",
            "step = 3600: loss = 4.644145800702591e+19\n",
            "step = 3800: loss = 4.985939105703736e+19\n",
            "step = 4000: loss = 5.630140769394439e+19\n",
            "step = 4000: Average Return = -13.87999439239502\n",
            "step = 4200: loss = 8.94874921660842e+19\n",
            "step = 4400: loss = 1.2876122067749883e+20\n",
            "step = 4600: loss = 1.1298514636719207e+20\n",
            "step = 4800: loss = 2.1734499345038836e+19\n",
            "step = 5000: loss = 8.662888507916891e+19\n",
            "step = 5000: Average Return = -13.029995918273926\n",
            "step = 5200: loss = 1.9108307026002838e+20\n",
            "step = 5400: loss = 2.8538621224953892e+20\n",
            "step = 5600: loss = 3.0482983513764135e+20\n",
            "step = 5800: loss = 2.604263835053494e+20\n",
            "step = 6000: loss = 3.661406090116402e+20\n",
            "step = 6000: Average Return = -14.509992599487305\n",
            "step = 6200: loss = 3.278475569112715e+20\n",
            "step = 6400: loss = 1.253414316518597e+20\n",
            "step = 6600: loss = 2.8953393954541693e+20\n",
            "step = 6800: loss = 3.303972276190608e+20\n",
            "step = 7000: loss = 2.949153188876596e+20\n",
            "step = 7000: Average Return = -12.179994583129883\n",
            "step = 7200: loss = 3.389124086145116e+20\n",
            "step = 7400: loss = 3.884413788352162e+20\n",
            "step = 7600: loss = 1.2339268363106858e+20\n",
            "step = 7800: loss = 7.1045682700560105e+19\n",
            "step = 8000: loss = 3.341280376978722e+20\n",
            "step = 8000: Average Return = -11.599995613098145\n",
            "step = 8200: loss = 1.3341629782280477e+20\n",
            "step = 8400: loss = 3.575486205319195e+20\n",
            "step = 8600: loss = 1.5500570121539577e+20\n",
            "step = 8800: loss = 5.3457361659418064e+20\n",
            "step = 9000: loss = 2.106999409962962e+20\n",
            "step = 9000: Average Return = -12.22999382019043\n",
            "step = 9200: loss = 1.723155326737989e+20\n",
            "step = 9400: loss = 2.3033799272456153e+20\n",
            "step = 9600: loss = 2.9651953274086385e+20\n",
            "step = 9800: loss = 1.7734955430259458e+20\n",
            "step = 10000: loss = 2.4963839762607636e+20\n",
            "step = 10000: Average Return = -14.479992866516113\n",
            "step = 10200: loss = 2.2632391326606295e+20\n",
            "step = 10400: loss = 1.850807219347899e+20\n",
            "step = 10600: loss = 5.0266248182514477e+20\n",
            "step = 10800: loss = 1.55849827078365e+20\n",
            "step = 11000: loss = 3.139411449493932e+20\n",
            "step = 11000: Average Return = -14.099993705749512\n",
            "step = 11200: loss = 2.356830090182504e+20\n",
            "step = 11400: loss = 1.9654996521863296e+20\n",
            "step = 11600: loss = 4.3630588196551446e+20\n",
            "step = 11800: loss = 2.184058990258899e+20\n",
            "step = 12000: loss = 3.911110282518284e+20\n",
            "step = 12000: Average Return = -14.579992294311523\n",
            "step = 12200: loss = 1.7123765943485753e+20\n",
            "step = 12400: loss = 3.046751998223109e+20\n",
            "step = 12600: loss = 1.8313002997744088e+20\n",
            "step = 12800: loss = 2.1716881650324655e+20\n",
            "step = 13000: loss = 1.8978946404362433e+20\n",
            "step = 13000: Average Return = -10.069995880126953\n",
            "step = 13200: loss = 9.762191668288265e+19\n",
            "step = 13400: loss = 7.490934896837893e+19\n",
            "step = 13600: loss = 8.863835253009233e+19\n",
            "step = 13800: loss = 1.663702885844606e+20\n",
            "step = 14000: loss = 7.819616745580134e+19\n",
            "step = 14000: Average Return = -14.739995956420898\n",
            "step = 14200: loss = 1.3071819304526571e+20\n",
            "step = 14400: loss = 9.545611627067553e+19\n",
            "step = 14600: loss = 6.0488853747864175e+19\n",
            "step = 14800: loss = 6.5776422758025e+19\n",
            "step = 15000: loss = 6.960733677347563e+19\n",
            "step = 15000: Average Return = -11.699995040893555\n",
            "step = 15200: loss = 9.334484283911307e+19\n",
            "step = 15400: loss = 8.884098812504493e+19\n",
            "step = 15600: loss = 1.0349206852609035e+20\n",
            "step = 15800: loss = 1.8403748771016999e+19\n",
            "step = 16000: loss = 3.470305427670329e+19\n",
            "step = 16000: Average Return = -15.079991340637207\n",
            "step = 16200: loss = 3.302247714192674e+19\n",
            "step = 16400: loss = 7.469425810570687e+19\n",
            "step = 16600: loss = 3.0347189429687288e+19\n",
            "step = 16800: loss = 6.599239322999928e+19\n",
            "step = 17000: loss = 1.921190960864166e+19\n",
            "step = 17000: Average Return = -13.12999439239502\n",
            "step = 17200: loss = 2.0660415023166783e+19\n",
            "step = 17400: loss = 2.1480663891627213e+19\n",
            "step = 17600: loss = 2.8375811260573286e+19\n",
            "step = 17800: loss = 4.604452111525924e+19\n",
            "step = 18000: loss = 1.4878439614460199e+19\n",
            "step = 18000: Average Return = -12.259995460510254\n",
            "step = 18200: loss = 2.558808309123095e+19\n",
            "step = 18400: loss = 2.3011817396189004e+19\n",
            "step = 18600: loss = 3.433006474818958e+19\n",
            "step = 18800: loss = 4.2001863700287324e+18\n",
            "step = 19000: loss = 1.7368181440977568e+19\n",
            "step = 19000: Average Return = -10.689995765686035\n",
            "step = 19200: loss = 6.714962701921026e+18\n",
            "step = 19400: loss = 1.0560157174393209e+19\n",
            "step = 19600: loss = 6.376976126077567e+18\n",
            "step = 19800: loss = 9.12453528736655e+18\n",
            "step = 20000: loss = 1.644943502236608e+19\n",
            "step = 20000: Average Return = -15.61999225616455\n",
            "step = 20200: loss = 6.91127335623485e+18\n",
            "step = 20400: loss = 8.27661336050244e+18\n",
            "step = 20600: loss = 3.832479720008581e+18\n",
            "step = 20800: loss = 1.2173896096828883e+19\n",
            "step = 21000: loss = 4.081691727025406e+18\n",
            "step = 21000: Average Return = -12.72999382019043\n",
            "step = 21200: loss = 5.724121855632081e+18\n",
            "step = 21400: loss = 4.756438923247354e+18\n",
            "step = 21600: loss = 8.195683807139987e+18\n",
            "step = 21800: loss = 2.5141930409737585e+18\n",
            "step = 22000: loss = 4.390650371261858e+18\n",
            "step = 22000: Average Return = -11.439994812011719\n",
            "step = 22200: loss = 5.336347194259669e+18\n",
            "step = 22400: loss = 3.730146798421934e+18\n",
            "step = 22600: loss = 2.769115911385252e+18\n",
            "step = 22800: loss = 2.061854781940433e+18\n",
            "step = 23000: loss = 3.3876184149220393e+18\n",
            "step = 23000: Average Return = -15.639989852905273\n",
            "step = 23200: loss = 2.2968806150577848e+18\n",
            "step = 23400: loss = 1.4977618861820477e+18\n",
            "step = 23600: loss = 1.8373681800921743e+18\n",
            "step = 23800: loss = 1.3519311850889544e+18\n",
            "step = 24000: loss = 1.0465459536427745e+18\n",
            "step = 24000: Average Return = -15.159991264343262\n",
            "step = 24200: loss = 7.307218213635359e+17\n",
            "step = 24400: loss = 1.0315517761358397e+18\n",
            "step = 24600: loss = 1.156577655647109e+18\n",
            "step = 24800: loss = 4.519351505827922e+17\n",
            "step = 25000: loss = 3.110286123146936e+17\n",
            "step = 25000: Average Return = -13.539993286132812\n",
            "step = 25200: loss = 3.228073711454126e+17\n",
            "step = 25400: loss = 3.832634338831237e+17\n",
            "step = 25600: loss = 5.2007216103397786e+17\n",
            "step = 25800: loss = 3.527077308693217e+17\n",
            "step = 26000: loss = 2.609883950255964e+17\n",
            "step = 26000: Average Return = -12.139995574951172\n",
            "step = 26200: loss = 3.236067848182825e+17\n",
            "step = 26400: loss = 2.702862776669307e+17\n",
            "step = 26600: loss = 1.3013526709587149e+17\n",
            "step = 26800: loss = 2.2170195121196237e+17\n",
            "step = 27000: loss = 1.557889950857298e+17\n",
            "step = 27000: Average Return = -11.699995040893555\n",
            "step = 27200: loss = 2.0583132549873664e+17\n",
            "step = 27400: loss = 1.74894057590358e+17\n",
            "step = 27600: loss = 1.3983396467520307e+17\n",
            "step = 27800: loss = 1.1988257886489805e+17\n",
            "step = 28000: loss = 1.2912746160979968e+17\n",
            "step = 28000: Average Return = -11.309995651245117\n",
            "step = 28200: loss = 1.8894897728926515e+17\n",
            "step = 28400: loss = 5.060063750678118e+16\n",
            "step = 28600: loss = 7.749034971024589e+16\n",
            "step = 28800: loss = 9.953595298414592e+16\n",
            "step = 29000: loss = 7.58561060641833e+16\n",
            "step = 29000: Average Return = -12.169995307922363\n",
            "step = 29200: loss = 1.4343802635209933e+17\n",
            "step = 29400: loss = 8.974810906361856e+16\n",
            "step = 29600: loss = 4.310594534506496e+16\n",
            "step = 29800: loss = 1.0297424610328576e+17\n",
            "step = 30000: loss = 1.0363770688136806e+17\n",
            "step = 30000: Average Return = -11.869996070861816\n",
            "step = 30200: loss = 5.537396108034048e+16\n",
            "step = 30400: loss = 7.607425604308173e+16\n",
            "step = 30600: loss = 5.217409877567078e+16\n",
            "step = 30800: loss = 1.4246943391744e+16\n",
            "step = 31000: loss = 4.069866342029722e+16\n",
            "step = 31000: Average Return = -10.24999713897705\n",
            "step = 31200: loss = 3.5559251866812416e+16\n",
            "step = 31400: loss = 2.757503007011635e+16\n",
            "step = 31600: loss = 1.1688005098012672e+16\n",
            "step = 31800: loss = 3.913258090522214e+16\n",
            "step = 32000: loss = 8876535612178432.0\n",
            "step = 32000: Average Return = -9.909997940063477\n",
            "step = 32200: loss = 9608710498287616.0\n",
            "step = 32400: loss = 2332951610130432.0\n",
            "step = 32600: loss = 2.2765205716992e+16\n",
            "step = 32800: loss = 5468906412048384.0\n",
            "step = 33000: loss = 1852348125151232.0\n",
            "step = 33000: Average Return = -12.369996070861816\n",
            "step = 33200: loss = 2738838904504320.0\n",
            "step = 33400: loss = 2315898710917120.0\n",
            "step = 33600: loss = 1449043448299520.0\n",
            "step = 33800: loss = 1829586006441984.0\n",
            "step = 34000: loss = 4343480025350144.0\n",
            "step = 34000: Average Return = -10.45999526977539\n",
            "step = 34200: loss = 5239154652741632.0\n",
            "step = 34400: loss = 1414154355212288.0\n",
            "step = 34600: loss = 1524388314742784.0\n",
            "step = 34800: loss = 567801655853056.0\n",
            "step = 35000: loss = 299124339507200.0\n",
            "step = 35000: Average Return = -10.989996910095215\n",
            "step = 35200: loss = 847470330380288.0\n",
            "step = 35400: loss = 683704301125632.0\n",
            "step = 35600: loss = 295573072642048.0\n",
            "step = 35800: loss = 221964144738304.0\n",
            "step = 36000: loss = 237003492818944.0\n",
            "step = 36000: Average Return = -11.359994888305664\n",
            "step = 36200: loss = 122899692257280.0\n",
            "step = 36400: loss = 367804993765376.0\n",
            "step = 36600: loss = 212280989974528.0\n",
            "step = 36800: loss = 524604082749440.0\n",
            "step = 37000: loss = 197123798728704.0\n",
            "step = 37000: Average Return = -11.76999568939209\n",
            "step = 37200: loss = 207495171670016.0\n",
            "step = 37400: loss = 44895981010944.0\n",
            "step = 37600: loss = 68283000684544.0\n",
            "step = 37800: loss = 100075892113408.0\n",
            "step = 38000: loss = 42603705794560.0\n",
            "step = 38000: Average Return = -12.149995803833008\n",
            "step = 38200: loss = 47939502211072.0\n",
            "step = 38400: loss = 60312984223744.0\n",
            "step = 38600: loss = 23413477343232.0\n",
            "step = 38800: loss = 29842496028672.0\n",
            "step = 39000: loss = 16518179979264.0\n",
            "step = 39000: Average Return = -10.519996643066406\n",
            "step = 39200: loss = 8861200154624.0\n",
            "step = 39400: loss = 7434388111360.0\n",
            "step = 39600: loss = 5977587843072.0\n",
            "step = 39800: loss = 6179471228928.0\n",
            "step = 40000: loss = 13482525196288.0\n",
            "step = 40000: Average Return = -10.449996948242188\n",
            "step = 40200: loss = 10444664209408.0\n",
            "step = 40400: loss = 8086603956224.0\n",
            "step = 40600: loss = 6090097950720.0\n",
            "step = 40800: loss = 3420782067712.0\n",
            "step = 41000: loss = 2343025246208.0\n",
            "step = 41000: Average Return = -11.85999584197998\n",
            "step = 41200: loss = 5084281831424.0\n",
            "step = 41400: loss = 1404124790784.0\n",
            "step = 41600: loss = 2146225881088.0\n",
            "step = 41800: loss = 2604632113152.0\n",
            "step = 42000: loss = 2088317747200.0\n",
            "step = 42000: Average Return = -9.979996681213379\n",
            "step = 42200: loss = 450914648064.0\n",
            "step = 42400: loss = 676431396864.0\n",
            "step = 42600: loss = 319241486336.0\n",
            "step = 42800: loss = 917722824704.0\n",
            "step = 43000: loss = 383009193984.0\n",
            "step = 43000: Average Return = -9.159997940063477\n",
            "step = 43200: loss = 234999103488.0\n",
            "step = 43400: loss = 256070090752.0\n",
            "step = 43600: loss = 182379184128.0\n",
            "step = 43800: loss = 82191876096.0\n",
            "step = 44000: loss = 79669297152.0\n",
            "step = 44000: Average Return = -12.639994621276855\n",
            "step = 44200: loss = 39275872256.0\n",
            "step = 44400: loss = 10747493376.0\n",
            "step = 44600: loss = 1707785984.0\n",
            "step = 44800: loss = 4390294528.0\n",
            "step = 45000: loss = 2668833536.0\n",
            "step = 45000: Average Return = -10.619997024536133\n",
            "step = 45200: loss = 2678362112.0\n",
            "step = 45400: loss = 2766979584.0\n",
            "step = 45600: loss = 1679716608.0\n",
            "step = 45800: loss = 2110277120.0\n",
            "step = 46000: loss = 1220592896.0\n",
            "step = 46000: Average Return = -10.269996643066406\n",
            "step = 46200: loss = 1122078720.0\n",
            "step = 46400: loss = 929543104.0\n",
            "step = 46600: loss = 2089441024.0\n",
            "step = 46800: loss = 1968705792.0\n",
            "step = 47000: loss = 1135847168.0\n",
            "step = 47000: Average Return = -13.509994506835938\n",
            "step = 47200: loss = 822577472.0\n",
            "step = 47400: loss = 1721816192.0\n",
            "step = 47600: loss = 1086718208.0\n",
            "step = 47800: loss = 1138839680.0\n",
            "step = 48000: loss = 794973312.0\n",
            "step = 48000: Average Return = -11.389996528625488\n",
            "step = 48200: loss = 795639232.0\n",
            "step = 48400: loss = 1329831680.0\n",
            "step = 48600: loss = 521211744.0\n",
            "step = 48800: loss = 1754737024.0\n",
            "step = 49000: loss = 1673522816.0\n",
            "step = 49000: Average Return = -16.539995193481445\n",
            "step = 49200: loss = 2975093504.0\n",
            "step = 49400: loss = 1279984896.0\n",
            "step = 49600: loss = 1400240640.0\n",
            "step = 49800: loss = 1104524288.0\n",
            "step = 50000: loss = 1435880192.0\n",
            "step = 50000: Average Return = -10.949995994567871\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  %%time\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step.\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "# Reset the environment.\n",
        "time_step = train_py_env.reset()\n",
        "\n",
        "# Create a driver to collect experience.\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    train_py_env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      agent.collect_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration)\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "    # Collect a few steps and save to the replay buffer.\n",
        "    time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "    # Sample a batch of data from the buffer and update the agent's network.\n",
        "    experience, unused_info = next(iterator)\n",
        "    train_loss = agent.train(experience).loss\n",
        "\n",
        "    step = agent.train_step_counter.numpy()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "      print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "    if step % eval_interval == 0:\n",
        "      avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "      print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "      returns.append(avg_return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HDMa0xH3rAS6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "72e59d03-5ccc-4d8e-edef-4ad46be2ad63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <video width=\"480\" height=\"480\" controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "    Your browser does not support the video tag.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "create_policy_eval_video(agent.policy, \"trained-agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsl0r1fyxpUD"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkOaR2zHrDwC"
      },
      "source": [
        "## TODO\n",
        "\n",
        "\n",
        "\n",
        "*   Check whether the `is_winner` function is correct\n",
        "*   Check whether the environment is correctly implement\n",
        "*   Add the variant in `step` function\n",
        "*   Test whether the agent always chooses an *empty* square and whether they can go to an adjacent place correctly\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM8uFtO055oodavEfdCc+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}